{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd5fb3b-212f-44d7-bed0-60d0e8e2c136",
   "metadata": {},
   "source": [
    "# HPC resource manager: Slurm\n",
    "\n",
    "Slurm, <https://slurm.schedmd.com/documentation.html>, is a resource\n",
    "manager and job scheduler that allows to organize and share resources in\n",
    "a HPC environment to get an optimal usage. It allows to specify usage\n",
    "policies, limits in terms of memory or cpu etc, to get metrics regarding\n",
    "the cluster usage, and so on. You can watch a good intro at\n",
    "<https://www.youtube.com/watch?v=NH_Fb7X6Db0> and related videos.\n",
    "\n",
    "Here we will use a very simple installation in the computer room. Our\n",
    "goal will be to learn some of the basic commands to get the possible\n",
    "resources, how to specify a partition, limits, resources and so on.\n",
    "\n",
    "**In general, you should run all cluster jobs through slurm, not run them directly on each node**.\n",
    "\n",
    "First of all, log into a client and use the command `sinfo` to get\n",
    "information about partitions:\n",
    "\n",
    "```sh\n",
    "sinfo --all\n",
    "```\n",
    "\n",
    "| PARTITION   | AVAIL | TIMELIMIT | NODES | STATE | NODELIST              |\n",
    "|-------------|-------|-----------|-------|-------|-----------------------|\n",
    "| 4threads    | up    | infinite  | 5     | idle  | sala[16-20]           |\n",
    "| 6threads    | up    | infinite  | 3     | idle  | sala[13-15]           |\n",
    "| 8threads    | up    | infinite  | 3     | idle  | sala[11-12,21]        |\n",
    "| 12threads*  | up    | infinite  | 8     | idle  | sala[7-10,26-29]      |\n",
    "| 16threads   | up    | infinite  | 9     | idle  | sala[2-6,22-25]       |\n",
    "| GPU         | up    | infinite  | 1     | idle  | sala2                 |\n",
    "\n",
    "\n",
    "As you can see in this example, there are several partitions available\n",
    "to be used. The `12threads` partition is the default. Some nodes\n",
    "might not working and will be shown as `down`. There is not time limit besides the login\n",
    "node (which actually should not be used for any job). Use the manual and\n",
    "get some other info about the resources.\n",
    "\n",
    "A more powerful cluster can be seen here:\n",
    "- https://www.nlhpc.cl/infraestructura/\n",
    "- https://dashboard.nlhpc.cl/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96761a41",
   "metadata": {},
   "source": [
    "\n",
    "To see the state of your running processes, use \n",
    "```sh\n",
    "squeue\n",
    "```\n",
    "\n",
    "Now let's run some simple commands in the cluster. To do so, we will use\n",
    "the simple command `srun` (check the manual)\n",
    "\n",
    "```sh\n",
    "srun hostname\n",
    "```\n",
    "\n",
    "As you can see here, the command actually ran in the `12threads`\n",
    "partition since we did not specify the actual partitions and `12threads`\n",
    "is the default.\n",
    "\n",
    "**Exercise**: Run 18 instances of the same command in a non-default\n",
    "partition. You should get something like (`12threads` partition)\n",
    "\n",
    "| SERVER              |\n",
    "|---------------------|\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala7.salafis.net   |\n",
    "| sala8.salafis.net   |\n",
    "| sala8.salafis.net   |\n",
    "| sala8.salafis.net   |\n",
    "| sala8.salafis.net   |\n",
    "| sala8.salafis.net   |\n",
    "| sala8.salafis.net   |\n",
    "| sala8.salafis.net   |\n",
    "| sala8.salafis.net   |\n",
    "\n",
    "Increase the number of jobs. Change the partition.\n",
    "\n",
    "As you can see, the jobs where magically distributed among two nodes\n",
    "necessary to run 18 processes (each node allows for 12 processes, two\n",
    "nodes corresponds to 24 processes in total). If you want to see this\n",
    "better, use the `stress` command with a timeout of 10 seconds and check\n",
    "that as soon as you launch the process, two nodes will be using their\n",
    "cpus at full (have some `htop` command running on both nodes):\n",
    "\n",
    "```sh\n",
    "srun -p 12threads -n 18  stress -t 10 -c 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137ded0",
   "metadata": {},
   "source": [
    "## Creating slurm scripts\n",
    "\n",
    "This is very useful, you can just distribute your commands among all the\n",
    "computers belonging to a given partition. But in general it is much\n",
    "better to write this commands in a script that could be reused.\n",
    "Actually, you can employ a special syntax in your script to give all\n",
    "the info to slurm and then use the command `sbatch` to launch your\n",
    "script , and `squeue` to check its state. You can use a script generator\n",
    "to make this task easier:\n",
    "\n",
    "-   <https://wiki.nlhpc.cl/Generador_Scripts>\n",
    "-   <https://www.hpc.iastate.edu/guides/classroom-hpc-cluster/slurm-job-script-generator>\n",
    "-   <https://hpc.nmsu.edu/home/tools/slurm-script-generator/>\n",
    "-   <https://www-app.igb.illinois.edu/tools/slurm/>\n",
    "-   <https://user.cscs.ch/access/running/jobscript_generator/>\n",
    "-   â€¦\n",
    "\n",
    "For our example we will need to generate and adapt to finally get\n",
    "something like\n",
    "\n",
    "```sh\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name=\"testmulti\"\n",
    "# #SBATCH --account=\"HerrComp\" # not used\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --mail-user=wfoquendop@unal.edu.co\n",
    "#SBATCH --time=01:00:00\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=12\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --partition=12threads\n",
    "\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "srun hostname\n",
    "```\n",
    "\n",
    "and then run it as\n",
    "\n",
    "```sh\n",
    "sbatch run.sh\n",
    "```\n",
    "\n",
    "You can get info about the jobs (if it is running, pending, cancelled,\n",
    "etc) using the command `squeue` .\n",
    "\n",
    "By default you will get the output written in some `*.out` file\n",
    "\n",
    "|              |\n",
    "|--------------|\n",
    "| Slurm.org    |\n",
    "| run.sh       |\n",
    "| slurm-70.out |\n",
    "\n",
    "Using a slurm script allows for a very general way to both run commands\n",
    "and specifiy , for instance, what modules to load, like using\n",
    "`ml somehpclib` or `spack load something`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb99236",
   "metadata": {},
   "source": [
    "\n",
    "## Exercises\n",
    "1. Create a script to run the stress command in some partition, including several nodes. Log into those nodes and check the actual usage. Share with other students.\n",
    "2. Create a slurm script to run the openmp vector average, also including the scalling study. Check if sharing the nodes affects or not the times measured.\n",
    "3. Create a slurm script to run the eigen matrix matmul example with openmp. Also use another one for the scaling study. \n",
    "4. Create a slurm script to run some program that needs `spack` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e58af",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
