{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1159057a-4ad7-4e47-8517-9ccc1e86876e",
   "metadata": {},
   "source": [
    "# Profiling\n",
    "\n",
    "After debugging your code and writing several tests to avoid repeating\n",
    "the same bug, you want to start optimizing it to make it fast (but\n",
    "keeping it correct). To do this, you need to measure. You need to detect\n",
    "functions which take most of the time. Optimizing a function that takes\n",
    "only 5% of the time will give you only marginal benefits. Finding the\n",
    "functions that take most of the time is called profiling , and there are\n",
    "several tools ready to help you. In the following we will learn to use\n",
    "these tools to detect the hotspots/bottlenecks in our codes. Please keep in mind tha [Computers are fast](https://computers-are-fast.github.io/), but your code might not be using all the resources in an efficient way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6ce4c2",
   "metadata": {},
   "source": [
    "\n",
    "## Why profile?\n",
    "\n",
    "Profiling allows you to learn how the computation time was spent and how\n",
    "the data flows in your program. This can be achieved by just printing\n",
    "the time spent on each section using some internal timers, or, better,\n",
    "by using a tool called \"profiler\" that shows you how time was spent in\n",
    "your program and which functions called which other functions.\n",
    "\n",
    "Using a profiler is something that comes very handy when you want to\n",
    "verify that your program does what you want it to do, especially when it\n",
    "is not easy to analyze (it may contain many functions or many calls to\n",
    "different functions and so on).\n",
    "\n",
    "Remember, WE ARE SCIENTISTS, so we want to profile code to optimize the\n",
    "computation time taken by our program. The key idea then becomes finding\n",
    "where (which function/subroutine) is the computation time spent and\n",
    "attack it using optimization techniques (studied in a previous session\n",
    "of this course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e5dd3",
   "metadata": {},
   "source": [
    "\n",
    "## Measuring the whole running time\n",
    "Take the following code as example (from <https://github.com/thehackerwithin/PyTrieste/tree/master/valgrind>)\n",
    "``` c++\n",
    "#include <cstdio>\n",
    "#include <cstdlib>\n",
    "\n",
    "/*\n",
    "  Tests cache misses.\n",
    "*/\n",
    "\n",
    "void option1(long * data, int m, int n);\n",
    "void option2(long * data, int m, int n);\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  if (argc < 3){\n",
    "    printf(\"Usage: cacheTest sizeI sizeJ\\nIn first input.\\n\");\n",
    "    return 1;\n",
    "  }\n",
    "  long sI = atoi(argv[1]);\n",
    "  long sJ = atoi(argv[2]);\n",
    "\n",
    "  printf(\"Operating on matrix of size %ld by %ld\\n\", sI, sJ);\n",
    "\n",
    "  long *arr = new long[sI*sJ]; // double array.\n",
    "\n",
    "  // option 1\n",
    "  option1(arr, sI, sJ);\n",
    "      \n",
    "  // option 2\n",
    "  option2(arr, sI, sJ);\n",
    "\n",
    "  // option 3\n",
    "  option3(arr, sI, sJ);\n",
    "\n",
    "  // why this?\n",
    "  printf(\"%ld\\n\", arr[0]);\n",
    "\n",
    "  // free memory\n",
    "  delete [] arr; \n",
    "\n",
    "  return 0;\n",
    "}\n",
    "\n",
    "void option1(long * data, int m, int n)\n",
    "{\n",
    "  for (long i=0; i < m; ++i)\n",
    "    for (long j=0; j < n; ++j)\n",
    "      data[(i * (n)) + j ] = i;\n",
    "}\n",
    "\n",
    "void option2(long * data, int m, int n)\n",
    "{\n",
    "  for (long i=0; i < m; ++i)\n",
    "    for (long j=0; j < n; ++j)\n",
    "      data[(j * (sI)) + i ] = i;\n",
    "}\n",
    "\n",
    "void option3(long * data, int m, int n)\n",
    "{\n",
    "  for (int i=0; i < m*n; ++i) data[i] = i;\n",
    "}\n",
    "\n",
    "```\n",
    "Read it and try to understand what it does. Now, compile and run it.\n",
    "\n",
    "If you want to measure the while running time against the matrix size, you can use the commands `time` or `/usr/bin/time`:\n",
    "```shell\n",
    "/usr/bin/time ./a.out 100 200\n",
    "```\n",
    "This will give you the total running clock time of the program. This is useful if the code is dominated by the computing part, not the memory allocation or similar things. Run it several times per size and observe the fluctuations. \n",
    "\n",
    "But, if you need to measure a more specific part of your code, it is much better to measure those parts directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b142abb",
   "metadata": {},
   "source": [
    "\n",
    "## Measuring elapsed time\n",
    "\n",
    "The first approach is to just add timers to your code. This is a good\n",
    "practice and it is useful for a code to report the time spent on\n",
    "different parts.  We will use the previous example and add watches at specific points, using `std::chrono` (you can see\n",
    "more examples <https://www.techiedelight.com/measure-elapsed-time-program-chrono-library/> and <https://en.cppreference.com/w/cpp/chrono/duration>. This allows to measure the **clock time**, not the **cpu time** (look for the differences ...) . Notice that `high_resolution_clock` is implementation defined, so it can be aliases to `system_clock`, which is not guaranteed to be steady. Beter use the `steady_clock`.  \n",
    "\n",
    "An example to use a timer is \n",
    "```c++\n",
    "auto start = std::chrono::steady_clock::now();\n",
    "option1(...);\n",
    "auto end = std::chrono::steady_clock::now();\n",
    "std::cout << (end-start).count() << \"\\n\"; // prints the time diff in seconds // better to print in scientific notation\n",
    "```\n",
    "\n",
    "### Exercise\n",
    "Add timers for all the previous function calls, including the memory allocation and freed. Compare with the total time.  Compile and run it . Now you have much better results, the granularity has increased and now you know where the code is spending most of the time.  Analyze the results.\n",
    "\n",
    "### Exercise\n",
    "Plot the time average time per option as function of the matriz size (use square matrices of size nxn, plot againts n). Explain the differences in complexity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6469f38",
   "metadata": {},
   "source": [
    "\n",
    "## Profilers\n",
    "\n",
    "There are many types of profilers from many different sources, commonly,\n",
    "a profiler is associated to a compiler, so that for example, GNU (the\n",
    "community around gcc compiler) has the profiler 'gprof', intel\n",
    "(corporation behind icc) has iprof, PGI has pgprof, etc. Valgrind is\n",
    "also a useful profiler through the cachegrind tool, which has been shown\n",
    "at the debugging section. There is also a very famous and important profile in linux, perf, which can help to generate [flame graphs](https://www.brendangregg.com/flamegraphs.html). \n",
    "\n",
    "This mini tutorial will focus on using gprof.\n",
    "Note that gprof supports (to some extend) compiled code by other\n",
    "compilers such as icc and pgcc. At the end we will briefly review perf,\n",
    "and the google performance tools.\n",
    "\n",
    "> **FACT 1:** According to Thiel, \"gprof … revolutionized the\n",
    "> performance analysis field and quickly became the tool of choice for\n",
    "> developers around the world …, the tool is still actively maintained\n",
    "> and remains relevant in the modern world.\" (from Wikipedia).\n",
    "\n",
    "> **FACT 2:** Top 50 most influential papers on PLDI (from Wikipedia).\n",
    "\n",
    "Here we will check some utilities like gprof, perf, and valgrind. But please notice that there are some other alternatives like\n",
    "- tracy: https://github.com/wolfpld/tracy\n",
    "- Papi (Performance api), <https://icl.utk.edu/papi/>\n",
    "- Perfetto, a solution provided by google: https://perfetto.dev/\n",
    "- memray, a python profiler : https://github.com/bloomberg/memray\n",
    "- The list is very large: <https://en.wikipedia.org/wiki/List_of_performance_analysis_tools?useskin=vector>\n",
    "\n",
    "In the following we will see some simple introductions to some of these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13631d3a-4026-44b9-be2a-7ae420628bcd",
   "metadata": {},
   "source": [
    "## An introduction to `gprof`\n",
    "\n",
    "The gnu profiler, [gprof](https://ftp.gnu.org/old-gnu/Manuals/gprof-2.9.1/html_mono/gprof.html), works pretty well with the gnu tools and allows to you to get a peerformance profile for your programs. To do so, the general approach is to\n",
    "\n",
    "1.  Compile with the flag `-pg`\n",
    "   ```shell\n",
    "   gcc -Wall -pg -g test_gprof.c -o test_gprof.x\n",
    "   ```\n",
    "\n",
    "2.  Execute normally. This will create or overwrite the file `gmon.out`\n",
    "    ``` shell\n",
    "    ./test_gprof.x\n",
    "    ```\n",
    "\n",
    "3.  Process the report as \n",
    "    ``` shell\n",
    "    gprof test_gprof.x gmon.out > analysis.txt\n",
    "    ```\n",
    "\n",
    "This produces a file called 'analysis.txt' which contains the profiling\n",
    "information in a human-readable form. The output of this file is  like the following:\n",
    "\n",
    "``` bash\n",
    "Flat profile:\n",
    "\n",
    "Each sample counts as 0.01 seconds.\n",
    "  %   cumulative   self              self     total\n",
    " time   seconds   seconds    calls   s/call   s/call  name\n",
    " 39.64      9.43     9.43        1     9.43    16.79  func1\n",
    " 30.89     16.79     7.35        1     7.35     7.35  new_func1\n",
    " 30.46     24.04     7.25        1     7.25     7.25  func2\n",
    "  0.13     24.07     0.03                             main\n",
    "\n",
    " %         the percentage of the total running time of the\n",
    "time       program used by this function.\n",
    "\n",
    "...\n",
    "\n",
    "             Call graph (explanation follows)\n",
    "\n",
    "\n",
    "granularity: each sample hit covers 2 byte(s) for 0.04% of 24.07 seconds\n",
    "\n",
    "index % time    self  children    called     name\n",
    "                                                 <spontaneous>\n",
    "[1]    100.0    0.03   24.04                 main [1]\n",
    "                9.43    7.35       1/1           func1 [2]\n",
    "                7.25    0.00       1/1           func2 [4]\n",
    "-----------------------------------------------\n",
    "                9.43    7.35       1/1           main [1]\n",
    "[2]     69.7    9.43    7.35       1         func1 [2]\n",
    "                7.35    0.00       1/1           new_func1 [3]\n",
    "-----------------------------------------------\n",
    "                7.35    0.00       1/1           func1 [2]\n",
    "[3]     30.5    7.35    0.00       1         new_func1 [3]\n",
    "-----------------------------------------------\n",
    "                7.25    0.00       1/1           main [1]\n",
    "[4]     30.1    7.25    0.00       1         func2 [4]\n",
    "-----------------------------------------------\n",
    "\n",
    " This table describes the call tree of the program, and was sorted by\n",
    " the total amount of time spent in each function and its children.\n",
    "\n",
    "...\n",
    "\f",
    "\n",
    "Index by function name\n",
    "\n",
    "   [2] func1                   [1] main\n",
    "   [4] func2                   [3] new_func1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb221bde-63b6-4d66-b76a-4456abdea6e1",
   "metadata": {},
   "source": [
    "The output has two sections: \n",
    "\n",
    "- *Flat profile:* The flat profile shows the total amount of time your program spent executing each function.\n",
    "- *Call graph:* The call graph shows how much time was spent in each function and its children.\n",
    "\n",
    "To create flamegraphs, you can try to setup a complicated script to transform the gprof output into something readable by the [flamegraphs](https://github.com/brendangregg/FlameGraph) scripts, or better use perf.  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe7273-fed3-4027-a0ee-7197085a82a3",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Create both the gprof analysisfor the previous code. Where would you focus your efforts to optimize this program?\n",
    "\n",
    "### Exercise\n",
    "Create both the gprof analysis for the following code. Where would you focus your efforts to optimize this program?\n",
    "``` c\n",
    "//test_gprof.c\n",
    "#include<stdio.h>\n",
    "\n",
    "void new_func1(void);\n",
    "void func1(void);\n",
    "static void func2(void);\n",
    "void new_func1(void);\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  printf(\"\\n Inside main()\\n\");\n",
    "  int i = 0;\n",
    "\n",
    "  for(;i<0xffffff;i++);\n",
    "  func1();\n",
    "  func2();\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "void new_func1(void);\n",
    "\n",
    "void func1(void)\n",
    "{\n",
    "  printf(\"\\n Inside func1 \\n\");\n",
    "  int i = 0;\n",
    "\n",
    "  for(;i<0xffffffff;i++);\n",
    "  new_func1();\n",
    "\n",
    "  return;\n",
    "}\n",
    "\n",
    "static void func2(void)\n",
    "{\n",
    "  printf(\"\\n Inside func2 \\n\");\n",
    "  int i = 0;\n",
    "\n",
    "  for(;i<0xffffffaa;i++);\n",
    "  return;\n",
    "}\n",
    "\n",
    "void new_func1(void)\n",
    "{\n",
    "  printf(\"\\n Inside new_func1()\\n\");\n",
    "  int i = 0;\n",
    "\n",
    "  for(;i<0xffffffee;i++);\n",
    "\n",
    "  return;\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5a798-ced8-4287-8989-edf36af7264b",
   "metadata": {},
   "source": [
    "## An introduction to `perf`\n",
    "[perf](https://perfwiki.github.io/main/) is powerful: it can instrument CPU performance counters, tracepoints, kprobes, and uprobes (dynamic tracing). It is capable of lightweight profiling. It is also included in the Linux kernel, under tools/perf, and is frequently updated and enhanced. (from <https://perf.wiki.kernel.org/index.php/Main_Page>)\n",
    "\n",
    "More about perf: https://www.brendangregg.com/perf.html , https://www.swift.org/documentation/server/guides/linux-perf.html\n",
    "\n",
    "It can also ve used in other languages, like python https://docs.python.org/3/howto/perf_profiling.html \n",
    "\n",
    "An example of fixing a program using perf: https://pkolaczk.github.io/server-slower-than-a-laptop/\n",
    "\n",
    "### Installing perf \n",
    "\n",
    "Perf is a kernel module, so you will need to install it from the kernel\n",
    "source. As root, the command used to install perl in the computer room\n",
    "was (this needs root privileges)\n",
    "\n",
    "``` shell\n",
    "cd /usr/src/linux/tools/perf/; make -j $(nproc); cp perf /usr/local/bin\n",
    "```\n",
    "\n",
    "This will copy the perf executable into the path.\n",
    "\n",
    "### Using perf\n",
    "\n",
    "Perf is a hardware counter available on linux platforms. NOTE: It is recommended to compile with `-fno-omit-frame-pointer`\n",
    "\n",
    "Its use is very simple: Just run, For a profile summary,\n",
    "\n",
    "``` shell\n",
    "perf stat ./a.out > profile_summary\n",
    "```\n",
    "\n",
    "For gprof-like info, use\n",
    "\n",
    "``` cpp\n",
    "perf record ./a.out\n",
    "perf report\n",
    "```\n",
    "\n",
    "This will generate something like\n",
    "\n",
    "<img src=\"fig/perf-report.png\" alt=\"\" width=\"50%\" align=\"center\">\n",
    "\n",
    "\n",
    "There are several command options \n",
    "- `perf stat`: obtain event counts\n",
    "- `perf record`: record events for later reporting\n",
    "- `perf report`: break down events by process, function, etc.\n",
    "- `perf annotate`: annotate assembly or source code with event counts\n",
    "- `perf top`: see live event count\n",
    "- `perf bench`: run different kernel microbenchmarks\n",
    "- \n",
    "Check <https://perfwiki.github.io/main/tutorial/> for more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d85b4-82f7-4a87-8360-6239a8537ff4",
   "metadata": {},
   "source": [
    "### Flamegraphs\n",
    "To generate a flamegraphs, you can use the scripts at <https://github.com/brendangregg/FlameGraph>. Let's assume that you have clone that repo inside the Downloads/ directory.\n",
    "```shell\n",
    "cd ~/Downloads/\n",
    "git clone https://github.com/brendangregg/FlameGraph\n",
    "```\n",
    "\n",
    "First you need tor run perf, like (perf arg `-a` requires kernel profile capability)\n",
    "```shell\n",
    "perf record --call-graph dwarf  -F 99 -g -- command arg1 arg2 ...\n",
    "```\n",
    "This command will generate a `perf.data` file in your current directory.\n",
    "\n",
    "Then you need to transform the perf.data data into a human readable file\n",
    "```bash\n",
    "perf script > out.perf\n",
    "```\n",
    "\n",
    "Now fold the stacks, to collapse identical calls\n",
    "```bash\n",
    "~/Downloads/FlameGraph/stackcollapse-perf.pl ./out.perf > out.folded\n",
    "```\n",
    "\n",
    "And, finally, generate the flamegraph\n",
    "```bash\n",
    "~/Downloads/FlameGraph/flamegraph.pl out.folded > flamegraph.svg\n",
    "```\n",
    "\n",
    "Open it with firefox or inkscape. You will get something like\n",
    "\n",
    "<img src=\"fig/flamegraph-1.png\" alt=\"\" width=\"90%\" align=\"center\">\n",
    "\n",
    "As you can see, the width is proportional to the time.\n",
    "\n",
    "\n",
    "### Exercise\n",
    "Generate the flamegraph for the previous code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041cc16-68b3-435c-999a-d550570df594",
   "metadata": {},
   "source": [
    "## Some guis for perf\n",
    "\n",
    "### Speedscope\n",
    "It can load the `perf.data` file and visualize it. Go to <https://www.speedscope.app/> and load your perf data. You can also go to the repo and download a local installation to be able to run all locally. It will show you something like\n",
    "\n",
    "Flamegraph:\n",
    "\n",
    "<img src=\"fig/speedscope-1.png\" alt=\"\" width=\"90%\" align=\"center\">\n",
    "\n",
    "Callgraph:\n",
    "\n",
    "<img src=\"fig/speedscope-2.png\" alt=\"\" width=\"90%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8816fb9b-82bb-47e3-bb0f-7fbe016da90a",
   "metadata": {},
   "source": [
    "#### Hotspot\n",
    "Please see <https://github.com/KDAB/hotspot>  and <https://www.kdab.com/hotspot-video/>.\n",
    "\n",
    "Install with the appimage: Download it from the releases at <https://github.com/KDAB/hotspot>. Then,  make it executable\n",
    "```bash\n",
    "chmod +x ~/Downloads/hotspot-v1.5.1-x86_64.AppImage\n",
    "```\n",
    "And, finally, run it. If you run it from the same directoy with the perf data, it will automatically load it, giving you all the data in a uniform gui.\n",
    "\n",
    "<img src=\"fig/hotspot-1.png\" alt=\"\" width=\"70%\" align=\"center\">\n",
    "\n",
    "<img src=\"fig/hotspot-2.png\" alt=\"\" width=\"70%\" align=\"center\">\n",
    "\n",
    "\n",
    "NOTE: In the computer room you can also use spack:\n",
    "\n",
    "``` shell\n",
    "spack load hotspot-perf\n",
    "```\n",
    "\n",
    "And then just use the command `hotspot` .\n",
    "\n",
    "### Exercise\n",
    "Create a flamegraph visualzation using both speedscope and hotspot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e2931",
   "metadata": {},
   "source": [
    "\n",
    "## Profiling with valgrind: cachegrind and callgrind\n",
    "\n",
    "Valgrind allows not only to debug a code but also to profile it. Here we\n",
    "will see how to use cachegrind, to check for cache misses, and\n",
    "callgrind, for a calling graph much like tools like perf and gprof.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96220b0c",
   "metadata": {},
   "source": [
    "\n",
    "### Cache checker : cachegrind\n",
    "From [cachegrind](http://valgrind.org/docs/manual/cg-manual.html#cg-manual.overview) \n",
    "> Cachegrind simulates how your program interacts with a machine's\n",
    "> cache hierarchy and (optionally) branch predictor. It simulates a\n",
    "> machine with independent first-level instruction and data caches (I1\n",
    "> and D1), backed by a unified second-level cache (L2). This exactly\n",
    "> matches the configuration of many modern machines.\n",
    "\n",
    "> However, some modern machines have three levels of cache. For these\n",
    "> machines (in the cases where Cachegrind can auto-detect the cache\n",
    "> configuration) Cachegrind simulates the first-level and third-level\n",
    "> caches. The reason for this choice is that the L3 cache has the most\n",
    "> influence on runtime, as it masks accesses to main memory.\n",
    "> Furthermore, the L1 caches often have low associativity, so simulating\n",
    "> them can detect cases where the code interacts badly with this cache\n",
    "> (eg. traversing a matrix column-wise with the row length being a power\n",
    "> of 2).\n",
    "\n",
    "> Therefore, Cachegrind always refers to the I1, D1 and LL (last-level)\n",
    "> caches.\n",
    "\n",
    "To use cachegrind, you will need to invoke valgrind as\n",
    "\n",
    "``` bash\n",
    "valgrind --tool=cachegrind prog\n",
    "```\n",
    "\n",
    "Take into account that execution will be (possibly very) slow.\n",
    "\n",
    "Typical output:\n",
    "\n",
    "``` bash\n",
    "==31751== I   refs:      27,742,716\n",
    "==31751== I1  misses:           276\n",
    "==31751== LLi misses:           275\n",
    "==31751== I1  miss rate:        0.0%\n",
    "==31751== LLi miss rate:        0.0%\n",
    "==31751==\n",
    "==31751== D   refs:      15,430,290  (10,955,517 rd + 4,474,773 wr)\n",
    "==31751== D1  misses:        41,185  (    21,905 rd +    19,280 wr)\n",
    "==31751== LLd misses:        23,085  (     3,987 rd +    19,098 wr)\n",
    "==31751== D1  miss rate:        0.2% (       0.1%   +       0.4%)\n",
    "==31751== LLd miss rate:        0.1% (       0.0%   +       0.4%)\n",
    "==31751==\n",
    "==31751== LL misses:         23,360  (     4,262 rd +    19,098 wr)\n",
    "==31751== LL miss rate:         0.0% (       0.0%   +       0.4%)\n",
    "```\n",
    "\n",
    "The output and more info will be written to `cachegrind.out.<pid>`,\n",
    "where pid is the PID of the process. You can open that file with\n",
    "valkyrie for better analysis.\n",
    "\n",
    "The tool `cg_annonate` allows you postprocess better the file\n",
    "`cachegrind.out.<pid>`.\n",
    "\n",
    "Compile the file cacheTest.cc,\n",
    "\n",
    "``` bash\n",
    "$ g++ -g cacheTest.cc -o cacheTest\n",
    "```\n",
    "\n",
    "Now run valgrind on it, with cache checker\n",
    "\n",
    "``` bash\n",
    "$ valgrind --tool=cachegrind ./cacheTest 0 1000 100000\n",
    "```\n",
    "\n",
    "Now let's check the cache-misses per line of source code:\n",
    "\n",
    "``` bash\n",
    "cg_annotate --auto=yes cachegrind.out.PID\n",
    "```\n",
    "\n",
    "where you have to change `PID` by the actual PID in your results.\n",
    "\n",
    "Fix the code.\n",
    "\n",
    "1.  More cache examples\n",
    "\n",
    "    Please open the file `cache.cpp` which is inside the directory\n",
    "    valgrind. Read it. Comment the line\n",
    "\n",
    "    ``` bash\n",
    "    std::sort(data, data + arraySize);\n",
    "    ```\n",
    "\n",
    "    Compile the program and run it, measuring the execution time (if you\n",
    "    wish, you can use optimization):\n",
    "\n",
    "    ``` bash\n",
    "    $ g++ -g cache.cpp -o cache.x\n",
    "    $ time ./cache.x\n",
    "    ```\n",
    "\n",
    "    The output will be something like\n",
    "\n",
    "    ``` bash\n",
    "    26.6758\n",
    "    sum = 312426300000\n",
    "\n",
    "    real    0m32.272s\n",
    "    user    0m26.560s\n",
    "    sys 0m0.122s\n",
    "    ```\n",
    "\n",
    "    Now uncomment the same line, re-compile and re-run. You will get\n",
    "    something like\n",
    "\n",
    "    ``` bash\n",
    "    5.37881\n",
    "    sum = 312426300000\n",
    "\n",
    "    real    0m6.180s\n",
    "    user    0m5.360s\n",
    "    sys 0m0.026s\n",
    "    ```\n",
    "\n",
    "    The difference is big. You can verify that this happens even with\n",
    "    compiler optimisations enabled. What it is going on here?\n",
    "\n",
    "    Try to figure out an explanation before continuing.\n",
    "\n",
    "    Now let's use valgrind to track the problem. Run the code (with the\n",
    "    sort line commented) with cachegrind:\n",
    "\n",
    "    ``` bash\n",
    "    $ valgrind --tool=cachegrind ./a.out\n",
    "    ```\n",
    "\n",
    "    And now let's annotate the code (remember to change PID for your\n",
    "    actual number):\n",
    "\n",
    "    ``` bash\n",
    "    cg_annonate --auto=yes cachegrind.out.PID\n",
    "    ```\n",
    "\n",
    "    We can see that we have something similar to [stackoverflow\n",
    "    analysis](http://goo.gl/gVwlj)\n",
    "\n",
    "    Understand why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12ebb73",
   "metadata": {},
   "source": [
    "\n",
    "### Callgrind\n",
    "\n",
    "Now, we are using valgrind to get a calling profile by using the tool\n",
    "`callgrind`. It is done as follows: Use the same program as in other\n",
    "modules. First, compile with debugging enabled, something like\n",
    "\n",
    "``` shell\n",
    "gcc -g -ggdb name.c -o name.x \n",
    "```\n",
    "\n",
    "and now execute with valgrind as\n",
    "\n",
    "``` shell\n",
    "valgrind --tool=callgrind name.x [possible options]\n",
    "```\n",
    "\n",
    "Results will be stored on the files `callgrind.out.PID`, where `PID` is\n",
    "the process identifier.\n",
    "\n",
    "You can read the previous file with a text editor, by using the\n",
    "instructions\n",
    "\n",
    "``` shell\n",
    "callgrind_annotate --auto=yes callgrind.out.PID\n",
    "```\n",
    "\n",
    "and you can also use the tool KCachegrind,\n",
    "\n",
    "``` shell\n",
    "kcachegrind callgrind.out.PID\n",
    "```\n",
    "\n",
    "(**do not forget to replace PID by the actual number**). The first view\n",
    "presents the list of the profiled functions. If you click on a function,\n",
    "other views appear with more info, as callers, calling map, source code,\n",
    "etc.\n",
    "\n",
    "*NOTE*: If you want to see correct function names, you can use the\n",
    "command\n",
    "\n",
    "``` shell\n",
    "valgrind --tool=callgrind --dump-instr=yes --collect-jumps=yes ./program program_parameters\n",
    "```\n",
    "\n",
    "Please run and use callgrind to study the previous programs and also a\n",
    "program using eigen library. In the later, it is easy to profile?\n",
    "\n",
    "This is a typical output from the kcachegrind page:\n",
    "\n",
    "<img src=\"https://kcachegrind.github.io/images/KcgShot3Large.gif\" width=60%>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed11440e",
   "metadata": {},
   "source": [
    "\n",
    "## Google Performance Tools\n",
    "\n",
    "See <https://github.com/gperftools/gperftools>\n",
    "\n",
    "From [Google performance\n",
    "tools](http://code.google.com/p/gperftools/?redir=1) : These tools are\n",
    "for use by developers so that they can create more robust applications.\n",
    "Especially of use to those developing multi-threaded applications in C++\n",
    "with templates. Includes TCMalloc, heap-checker, heap-profiler and\n",
    "cpu-profiler.\n",
    "\n",
    "In brief:\n",
    "\n",
    "``` bash\n",
    "TC Malloc:\n",
    "\n",
    "gcc [...] -ltcmalloc\n",
    "Heap Checker:\n",
    "\n",
    "gcc [...] -o myprogram -ltcmalloc\n",
    "HEAPCHECK=normal ./myprogram\n",
    "Heap Profiler:\n",
    "\n",
    "gcc [...] -o myprogram -ltcmalloc\n",
    "HEAPPROFILE=/tmp/netheap ./myprogram\n",
    "Cpu Profiler:\n",
    "\n",
    "gcc [...] -o myprogram -lprofiler\n",
    "CPUPROFILE=/tmp/profile ./myprogram\n",
    "```\n",
    "\n",
    "Basically, when ypu compile, you link with the required library. Then,\n",
    "you can generate a callgraph with profiler info. Try to install the\n",
    "google performance tool on your home and test them with the previous\n",
    "codes. Please review the detailed info for each tool: for example, for\n",
    "the cpu profiler, check [Cpu profiler\n",
    "info](http://google-perftools.googlecode.com/svn/trunk/doc/cpuprofile.html)\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1.  Take [this\n",
    "    code](https://bitbucket.org/iluvatar/scientific-computing-part-01/raw/9e1e2822cf7a6012b56708294eda1a5d3e0553b1/optimization/cache_lines.c)\n",
    "    and modify it (separate its behaviour into functions) to be able to\n",
    "    profile it.\n",
    "2.  Download\n",
    "    <https://bitbucket.org/iluvatar/scientific-computing-part-01/downloads/CodigosIvan.zip>,\n",
    "    run , and optimize them.\n",
    "3.  Experiment: Take [this\n",
    "    code](https://www.dropbox.com/s/qpphj2vzizzr7cl/oscilador.cpp),\n",
    "    profile it and try to optimize it in any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233acfcd-bc7b-4c29-9fc9-d49c9616d2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
